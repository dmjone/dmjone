<!-------------------------- © 2007 - present, dmj.one and contributors. ----------------------------------
   Part of the dmjone project. Licensed under the GNU AGPL. Provided as-is, without warranty of any kind. 
-------------------- Redistribution and modifications must retain this notice. --------------------------->


<!DOCTYPE html>
<!--[if lte 8]><html class="pre-ie9" lang="en"><![endif]-->
<!--[if gte IE 9]><!-->
<html lang="en">
	<!--<![endif]-->

	<head>
		<script src="/js/edu_su_common.js"></script>
		<noscript>
			<style>
				html,
				body {
					margin: 0;
					overflow: hidden;
				}
			</style>
			<iframe src="/frame_noscript.html" style="width:100%;height:100vh;border:none;display:block"></iframe>
		</noscript>

		<title>Docker - CSU677 - Shoolini U</title>
		<meta name="description" content="Learn about Docker, a platform that allows you to develop, ship, and run applications in containers.">

		<meta property=" og:image" content="/logo.png">
		<meta property="og:type" content="article">

		<meta name="twitter:card" content="summary">
		<meta name="twitter:site" content="@divyamohan1993">
		<meta name="twitter:creator" content="@divyamohan1993">
		<meta name="twitter:image" content="/logo.png">

		<meta charset="UTF-8" />
		<meta name="viewport" content="width=device-width,initial-scale=1" />

		<meta name="author" content="Divya Mohan">
		<meta name="robots" content="index, follow">

	</head>

	<body>

		<script> header_author("dm"); </script>

		<main>
			<article class="agen-tableofcontents">
				<h2 class="text-center">Docker</h2>
			</article>

			<article>
				<h3>1. Introduction to Docker</h3>
				<p>Docker is an open-source platform that automates the deployment, scaling, and management of applications using containerization. Containers are lightweight, portable, and self-sufficient units that package an application along with all its dependencies, ensuring consistency across different environments. Docker has become a key tool in DevOps, simplifying the process of application development, deployment, and scaling.</p>
			</article>

			<article>
				<h3>2. Understanding Containers</h3>
				<p>Containers are at the core of Docker. They provide a standardized environment for running applications by encapsulating the application code, libraries, dependencies, and configuration files. Unlike virtual machines, containers share the host system's kernel, making them more efficient and faster to start.</p>

				<h4>2.1 Containers vs. Virtual Machines</h4>
				<p>While both containers and virtual machines allow for isolated environments, they differ in several ways:</p>
				<ul>
					<li><strong>Architecture:</strong> Virtual machines include a full operating system along with the application, while containers share the host system's OS kernel.</li>
					<li><strong>Resource Efficiency:</strong> Containers are more lightweight and use fewer resources compared to virtual machines, as they don’t need to boot an entire OS.</li>
					<li><strong>Portability:</strong> Containers are highly portable and can run consistently across different environments, whereas virtual machines require more effort to migrate.</li>
				</ul>

				<h4>2.2 How Containers Work</h4>
				<p>Containers are built using Docker images, which are read-only templates containing the application and its dependencies. When a container is started, Docker creates a writable layer on top of the image, where any changes made during runtime are stored.</p>

				<h5>2.2.1 Example of a Simple Dockerfile</h5>
				<pre><code class="language-dockerfile">
# Use an official Node.js image as the base image
FROM node:14

# Set the working directory
WORKDIR /app

# Copy the package.json and install dependencies
COPY package.json .
RUN npm install

# Copy the application code
COPY . .

# Expose the port the app runs on
EXPOSE 3000

# Command to run the application
CMD ["npm", "start"]
</code></pre>
				<p>This Dockerfile defines a simple Node.js application container that installs dependencies, copies the code, and runs the application on port 3000.</p>
			</article>

			<article>
				<h3>3. Docker Images</h3>
				<p>Docker images are the building blocks of containers. They are immutable templates that include everything needed to run an application, such as the code, runtime, libraries, and environment variables.</p>

				<h4>3.1 Creating Docker Images</h4>
				<p>Docker images are created using Dockerfiles, which are scripts that contain a series of instructions to build the image. These instructions specify the base image, application dependencies, configurations, and the command to run the application.</p>

				<h5>3.1.1 Example of Building an Image</h5>
				<pre><code class="language-bash">
docker build -t my-node-app .
</code></pre>
				<p>This command builds a Docker image named <code>my-node-app</code> from the Dockerfile in the current directory.</p>

				<h4>3.2 Docker Image Layers</h4>
				<p>Each instruction in a Dockerfile creates a new layer in the Docker image. Layers are cached, which means that if a layer has not changed, Docker can reuse it, making the build process faster. This also enables more efficient storage and transfer of images.</p>

				<h4>3.3 Docker Hub</h4>
				<p>Docker Hub is a cloud-based registry service where Docker images can be stored and shared. Developers can push their images to Docker Hub and pull them to different environments as needed.</p>

				<h5>3.3.1 Example of Pushing an Image to Docker Hub</h5>
				<pre><code class="language-bash">
docker login
docker tag my-node-app username/my-node-app
docker push username/my-node-app
</code></pre>
				<p>This sequence logs into Docker Hub, tags the image, and pushes it to a repository under the user's account.</p>
			</article>

			<article>
				<h3>4. Docker Containers</h3>
				<p>Once an image is built, it can be used to create a Docker container. Containers are running instances of Docker images, and they can be started, stopped, and managed using Docker commands.</p>

				<h4>4.1 Running Containers</h4>
				<p>To run a Docker container, use the <code>docker run</code> command, specifying the image and any necessary options such as port mappings, environment variables, or volumes.</p>

				<h5>4.1.1 Example of Running a Container</h5>
				<pre><code class="language-bash">
docker run -d -p 3000:3000 --name my-running-app my-node-app
</code></pre>
				<p>This command runs a container from the <code>my-node-app</code> image, mapping port 3000 on the host to port 3000 in the container, and names the container <code>my-running-app</code>.</p>

				<h4>4.2 Managing Containers</h4>
				<p>Docker provides several commands to manage containers, such as listing running containers, stopping or restarting containers, and removing containers when they are no longer needed.</p>

				<h5>4.2.1 Common Container Management Commands</h5>
				<ul>
					<li><code>docker ps</code>: Lists all running containers.</li>
					<li><code>docker stop &lt;container_name&gt;</code>: Stops a running container.</li>
					<li><code>docker rm &lt;container_name&gt;</code>: Removes a stopped container.</li>
					<li><code>docker logs &lt;container_name&gt;</code>: Displays the logs of a container.</li>
				</ul>
			</article>

			<article>
				<h3>5. Docker Volumes</h3>
				<p>Docker volumes are used to persist data generated by a container, allowing it to be stored outside of the container’s filesystem. Volumes are the preferred way to manage data in Docker because they are independent of the container lifecycle and can be shared between multiple containers.</p>

				<h4>5.1 Creating and Using Volumes</h4>
				<p>Volumes can be created and attached to containers using the <code>docker volume</code> command. They can be mounted to specific directories inside the container to store data that should persist even after the container is stopped or removed.</p>

				<h5>5.1.1 Example of Using a Volume</h5>
				<pre><code class="language-bash">
docker volume create my-volume
docker run -d -p 3000:3000 -v my-volume:/app/data --name app-with-volume my-node-app
</code></pre>
				<p>This command creates a volume named <code>my-volume</code> and attaches it to the <code>/app/data</code> directory in the container.</p>

				<h4>5.2 Bind Mounts vs. Volumes</h4>
				<p>Docker supports both bind mounts and volumes for managing data:</p>
				<ul>
					<li><strong>Bind Mounts:</strong> Directly map a directory or file on the host to a directory or file in the container. Changes on the host are reflected in the container and vice versa.</li>
					<li><strong>Volumes:</strong> Managed by Docker and stored in a specific location on the host. Volumes offer better isolation and are more portable across different environments.</li>
				</ul>
			</article>

			<article>
				<h3>6. Docker Networking</h3>
				<p>Docker provides networking capabilities that allow containers to communicate with each other, with the host machine, and with external networks. Docker automatically creates a bridge network when it starts, which connects all running containers to the host and each other.</p>

				<h4>6.1 Docker Network Types</h4>
				<p>Docker supports several types of networks:</p>
				<ul>
					<li><strong>Bridge Network:</strong> The default network type. Containers on the same bridge network can communicate with each other using their container names.</li>
					<li><strong>Host Network:</strong> Containers share the network stack with the host, allowing for better performance but reducing isolation.</li>
					<li><strong>Overlay Network:</strong> Used for multi-host networking in a Docker Swarm or Kubernetes setup, allowing containers on different hosts to communicate securely.</li>
					<li><strong>Macvlan Network:</strong> Allows containers to appear as physical devices on the network, with their own MAC addresses.</li>
				</ul>

				<h5>6.1.1 Example of Creating and Using a Custom Network</h5>
				<pre><code class="language-bash">
docker network create my-network
docker run -d --name db --network my-network postgres
docker run -d --name web --network my-network my-node-app
</code></pre>
				<p>This example creates a custom network named <code>my-network</code> and connects two containers to it, allowing them to communicate with each other.</p>
			</article>

			<article>
				<h3>7. Docker Compose</h3>
				<p>Docker Compose is a tool that simplifies the process of managing multi-container Docker applications. It allows you to define and run multi-container applications using a YAML file, where you specify the services, networks, and volumes needed for the application.</p>

				<h4>7.1 Docker Compose File</h4>
				<p>A Docker Compose file is written in YAML and defines the configuration for your application’s services, including the images to use, the ports to expose,

					the volumes to mount, and the networks to connect.</p>

				<h5>7.1.1 Example of a Docker Compose File</h5>
				<pre><code class="language-yaml">
version: '3'
services:
  web:
    image: my-node-app
    ports:
      - "3000:3000"
    volumes:
      - ./app:/app
  db:
    image: postgres
    environment:
      POSTGRES_PASSWORD: example
</code></pre>
				<p>This Docker Compose file defines two services: a web service running a Node.js application and a database service running PostgreSQL.</p>

				<h4>7.2 Running Docker Compose</h4>
				<p>Once the Docker Compose file is defined, you can use Docker Compose commands to manage the entire application:</p>
				<ul>
					<li><code>docker-compose up</code>: Builds, (re)creates, starts, and attaches to containers for a service.</li>
					<li><code>docker-compose down</code>: Stops and removes containers, networks, volumes, and images created by <code>docker-compose up</code>.</li>
					<li><code>docker-compose logs</code>: Shows the logs for all services in the Docker Compose file.</li>
				</ul>
			</article>

			<article>
				<h3>8. Docker Swarm and Orchestration</h3>
				<p>Docker Swarm is Docker’s native clustering and orchestration tool. It allows you to manage a cluster of Docker engines as a single virtual host. Docker Swarm enables the deployment, scaling, and management of multi-container applications across multiple hosts.</p>

				<h4>8.1 Setting Up a Docker Swarm</h4>
				<p>To create a Docker Swarm, you initialize it on a Docker host and add other hosts as nodes to the swarm. The swarm manager orchestrates the distribution of containers across the nodes.</p>

				<h5>8.1.1 Example of Initializing a Swarm</h5>
				<pre><code class="language-bash">
docker swarm init --advertise-addr <manager-ip>
docker swarm join --token <token> <manager-ip>:2377
</code></pre>
				<p>This initializes a Docker Swarm on the manager and joins other nodes to the swarm using a token.</p>

				<h4>8.2 Deploying Services in a Swarm</h4>
				<p>In Docker Swarm, services are the tasks that run on the swarm nodes. You can deploy services using Docker commands or Docker Compose files.</p>

				<h5>8.2.1 Example of Deploying a Service</h5>
				<pre><code class="language-bash">
docker service create --name my-web-app --replicas 3 -p 80:80 my-node-app
</code></pre>
				<p>This command deploys a service running three replicas of a Node.js application on port 80.</p>

				<h4>8.3 Scaling Services</h4>
				<p>One of the key features of Docker Swarm is the ability to scale services up or down based on demand. You can adjust the number of replicas running across the swarm with a simple command.</p>

				<h5>8.3.1 Example of Scaling a Service</h5>
				<pre><code class="language-bash">
docker service scale my-web-app=5
</code></pre>
				<p>This command scales the <code>my-web-app</code> service to run five replicas.</p>
			</article>

			<article>
				<h3>9. Security in Docker</h3>
				<p>Security is a critical aspect of Docker, especially when running containers in production environments. Docker provides several security features to help isolate containers, protect data, and secure communications.</p>

				<h4>9.1 Namespaces and Control Groups (cgroups)</h4>
				<p>Docker uses Linux namespaces and control groups to isolate containers from each other and the host system. Namespaces provide isolation for resources like process IDs, network interfaces, and file systems, while control groups limit the resources (CPU, memory, I/O) that a container can use.</p>

				<h4>9.2 Securing Docker Images</h4>
				<p>Securing Docker images involves using trusted base images, minimizing the attack surface by installing only necessary software, and regularly updating and scanning images for vulnerabilities.</p>

				<h4>9.3 Docker Content Trust (DCT)</h4>
				<p>Docker Content Trust allows you to use digital signatures to verify the integrity and authenticity of Docker images. This ensures that only trusted images are used in your environment.</p>

				<h5>9.3.1 Enabling Docker Content Trust</h5>
				<pre><code class="language-bash">
export DOCKER_CONTENT_TRUST=1
</code></pre>
				<p>This command enables Docker Content Trust, ensuring that all pulled or pushed images are signed and verified.</p>

				<h4>9.4 Secrets Management</h4>
				<p>Docker provides a secure way to manage sensitive data like passwords, API keys, and certificates using Docker secrets. Secrets are encrypted and stored securely, and they can be injected into containers at runtime.</p>

				<h5>9.4.1 Example of Creating and Using a Secret</h5>
				<pre><code class="language-bash">
echo "my_secret_password" | docker secret create db_password -
docker service create --name my-db --secret db_password postgres
</code></pre>
				<p>This creates a secret named <code>db_password</code> and makes it available to the <code>my-db</code> service.</p>
			</article>

			<article>
				<h3>10. Best Practices for Docker</h3>
				<p>Following best practices when using Docker ensures that your containers are efficient, secure, and easy to manage.</p>

				<h4>10.1 Keep Images Small</h4>
				<p>Smaller images are faster to build, transfer, and deploy. Use minimal base images, and only include the necessary dependencies for your application.</p>

				<h4>10.2 Use Multi-Stage Builds</h4>
				<p>Multi-stage builds allow you to use multiple <code>FROM</code> statements in a Dockerfile, enabling the separation of build-time dependencies from the final image. This reduces the size of the final image by excluding unnecessary files and tools.</p>

				<h4>10.3 Tag Images Properly</h4>
				<p>Tagging images with meaningful and versioned tags helps in identifying and managing different versions of your application. Avoid using the <code>latest</code> tag for production deployments, as it can lead to unpredictability.</p>

				<h4>10.4 Clean Up Resources</h4>
				<p>Regularly clean up unused images, containers, volumes, and networks to free up disk space and improve Docker’s performance.</p>

				<h5>10.4.1 Example of Cleaning Up Resources</h5>
				<pre><code class="language-bash">
docker system prune -a
</code></pre>
				<p>This command removes all stopped containers, unused networks, dangling images, and optionally, all unused images.</p>
			</article>
			
		</main>

		<script> copyright("all"); </script>


	</body>

</html>