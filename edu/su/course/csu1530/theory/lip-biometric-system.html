<!-------------------------- © 2007 - present, dmj.one and contributors. ----------------------------------
   Part of the dmjone project. Licensed under the GNU AGPL. Provided as-is, without warranty of any kind. 
-------------------- Redistribution and modifications must retain this notice. --------------------------->


<!DOCTYPE html>
<!--[if lte 8]><html class="pre-ie9" lang="en"><![endif]-->
<!--[if gte IE 9]><!-->
<html lang="en">
    <!--<![endif]-->

    <head>
        <script src="/js/edu_su_common.js"></script>
        <noscript>
            <style>
                html,
                body {
                    margin: 0;
                    overflow: hidden;
                }
            </style>
            <iframe src="/frame_noscript.html" style="width:100%;height:100vh;border:none;display:block"></iframe>
        </noscript>

        <title>Lip Biometric System - CSU1530 - Shoolini U</title>
        <meta name="description" content="Learn about the theory and implementation of lip biometric systems in the context of CSU1530 at Shoolini University.">

        <meta property="og:image" content="/logo.png">
        <meta property="og:type" content="article">

        <meta name="twitter:card" content="summary">
        <meta name="twitter:site" content="@divyamohan1993">
        <meta name="twitter:creator" content="@divyamohan1993">
        <meta name="twitter:image" content="/logo.png">

        <meta charset="UTF-8" />
        <meta name="viewport" content="width=device-width,initial-scale=1" />

        <meta name="author" content="Divya Mohan">
        <meta name="robots" content="index, follow">

        <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.4/katex.min.js" integrity="sha512-sHSNLECRJSK+BFs7E8DiFc6pf6n90bLI85Emiw1jhreduZhK3VXgq9l4kAt9eTIHYAcuQBKHL01QKs4/3Xgl8g==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.4/contrib/auto-render.min.js" integrity="sha512-iWiuBS5nt6r60fCz26Nd0Zqe0nbk1ZTIQbl3Kv7kYsX+yKMUFHzjaH2+AnM6vp2Xs+gNmaBAVWJjSmuPw76Efg==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
        <script>
            document.addEventListener("DOMContentLoaded", function () {
                renderMathInElement(document.body, {
                    // customised options
                    // • auto-render specific keys, e.g.:
                    delimiters: [
                        { left: '$$', right: '$$', display: true },
                        { left: '$', right: '$', display: false },
                        { left: '\\(', right: '\\)', display: false },
                        { left: '\\[', right: '\\]', display: true }
                    ],
                    // • rendering keys, e.g.:
                    throwOnError: false
                });
            });
        </script>

    </head>

    <body>

        <script> header_author("dm"); </script>

        <main>
            <article class="agen-tableofcontents">
                <h2 class="text-center">
                    Lip Biometric System
                </h2>
                <div class="d-none contentdate">2024, September 20</div>
            </article>

            <article>
                <h3>1. Introduction to Lip Biometric Systems</h3>
                <p>Lip Biometric Systems identify or verify individuals by analyzing the unique features of their lips. The shape, texture, and movement patterns of lips provide distinctive characteristics useful for security and authentication applications.</p>
                <p>Applications include:</p>
                <ul>
                    <li><strong>Access Control</strong>: Securing entry to facilities or devices through lip-based verification.</li>
                    <li><strong>Speaker Verification</strong>: Enhancing speech recognition systems by incorporating visual lip data.</li>
                    <li><strong>Forensic Analysis</strong>: Assisting in criminal investigations by matching lip patterns.</li>
                </ul>
            </article>

            <article>
                <h3>2. Anatomy and Features of the Lips</h3>
                <p>The human lips possess features that are unique to each individual, making them suitable for biometric recognition.</p>
            </article>

            <article>
                <h4>2.1 Unique Characteristics</h4>
                <p>Distinctive features of the lips include:</p>
                <ul>
                    <li><strong>Shape and Contour</strong>: The overall outline and curvature of the lips vary among individuals.</li>
                    <li><strong>Texture Patterns</strong>: The grooves and wrinkles on the lip surface create unique patterns.</li>
                    <li><strong>Color Distribution</strong>: Variations in pigmentation contribute to individual differences.</li>
                </ul>
            </article>

            <article>
                <h4>2.2 Dynamics of Lip Movement</h4>
                <p>The way a person moves their lips during speech or expression adds another layer of uniqueness.</p>
                <p>Aspects to consider:</p>
                <ul>
                    <li><strong>Articulation Patterns</strong>: Individual differences in lip movement while speaking.</li>
                    <li><strong>Expression Dynamics</strong>: Variations in how expressions are formed.</li>
                </ul>
            </article>

            <article>
                <h3>3. Image Acquisition in Lip Biometrics</h3>
                <p>Capturing high-quality lip images or videos is crucial for accurate recognition.</p>
            </article>

            <article>
                <h4>3.1 Acquisition Methods</h4>
                <p>Techniques for capturing lip data include:</p>
                <ul>
                    <li><strong>Standard Cameras</strong>: Using cameras to record still images or videos of the lips.</li>
                    <li><strong>Infrared Imaging</strong>: Capturing thermal patterns of the lips, useful in low-light conditions.</li>
                    <li><strong>High-Speed Cameras</strong>: Recording rapid lip movements for dynamic analysis.</li>
                </ul>
            </article>

            <article>
                <h4>3.2 Challenges in Acquisition</h4>
                <p>Potential issues during data capture:</p>
                <ul>
                    <li><strong>Lighting Conditions</strong>: Inadequate lighting can affect image quality.</li>
                    <li><strong>Occlusions</strong>: Facial hair, hands, or objects may block the lips.</li>
                    <li><strong>Pose Variations</strong>: Different head positions can change the lip's appearance.</li>
                </ul>
                <p>Mitigation strategies involve controlled environments and consistent capture protocols.</p>
            </article>

            <article>
                <h3>4. Preprocessing of Lip Images</h3>
                <p>Preprocessing enhances lip images and prepares them for feature extraction.</p>
            </article>

            <article>
                <h4>4.1 Image Enhancement</h4>
                <p>Improving image quality through:</p>
                <ul>
                    <li><strong>Contrast Adjustment</strong>: Enhancing differences in intensity to highlight lip features.</li>
                    <li><strong>Noise Reduction</strong>: Applying filters to remove unwanted artifacts.</li>
                    <li><strong>Edge Enhancement</strong>: Sharpening edges to delineate the lip boundaries.</li>
                </ul>
            </article>

            <article>
                <h4>4.2 Lip Detection and Segmentation</h4>
                <p>Isolating the lip region from the rest of the image.</p>
                <p>Methods include:</p>
                <ul>
                    <li><strong>Color-Based Segmentation</strong>: Utilizing color differences between lips and surrounding skin.</li>
                    <li><strong>Active Shape Models</strong>: Statistical models that capture the variability of lip shapes.</li>
                    <li><strong>Deep Learning Approaches</strong>: Using convolutional neural networks for accurate detection.</li>
                </ul>
                <pre><code class="language-python">import cv2
import numpy as np

# Read the image
image = cv2.imread('face_image.jpg')
# Convert to HSV color space
hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
# Define color range for lips
lower_red = np.array([0, 50, 50])
upper_red = np.array([10, 255, 255])
# Create a mask
mask = cv2.inRange(hsv, lower_red, upper_red)
# Apply the mask
lip_region = cv2.bitwise_and(image, image, mask=mask)
</code></pre>
            </article>

            <article>
                <h3>5. Feature Extraction in Lip Biometrics</h3>
                <p>Extracting features from the lips to create a representative feature vector.</p>
            </article>

            <article>
                <h4>5.1 Geometric Features</h4>
                <p>Analyzing the shape and structure of the lips.</p>
                <p>Features include:</p>
                <ul>
                    <li><strong>Lip Contour</strong>: Extracting the outline of the lips and measuring geometric properties.</li>
                    <li><strong>Landmark Points</strong>: Identifying key points such as lip corners and peaks.</li>
                    <li><strong>Distance Ratios</strong>: Calculating ratios between distances of landmarks to capture shape characteristics.</li>
                </ul>
            </article>

            <article>
                <h4>5.2 Appearance-Based Features</h4>
                <p>Using pixel intensity values and texture patterns.</p>
                <p>Methods:</p>
                <ul>
                    <li><strong>Principal Component Analysis (PCA)</strong>: Reducing dimensionality while preserving significant variance.</li>
                    <li><strong>Discrete Cosine Transform (DCT)</strong>: Transforming spatial data into frequency components.</li>
                </ul>
                <p>DCT of a 2D image \( f(x,y) \):</p>
                <p>$$ F(u,v) = \alpha(u) \alpha(v) \sum_{x=0}^{N-1} \sum_{y=0}^{N-1} f(x,y) \cos\left[\frac{\pi (2x + 1)u}{2N}\right] \cos\left[\frac{\pi (2y + 1)v}{2N}\right] $$</p>
                <ul>
                    <li><strong>\( \alpha(u) \)</strong>: Normalization factor.</li>
                    <li><strong>\( N \)</strong>: Image dimension.</li>
                </ul>
            </article>

            <article>
                <h4>5.3 Dynamic Features</h4>
                <p>Capturing movement patterns during speech or expressions.</p>
                <p>Techniques:</p>
                <ul>
                    <li><strong>Optical Flow Analysis</strong>: Measuring motion between consecutive frames.</li>
                    <li><strong>Hidden Markov Models (HMM)</strong>: Modeling temporal sequences of lip movements.</li>
                </ul>
                <p>Optical flow equation:</p>
                <p>$$ I_x u + I_y v + I_t = 0 $$</p>
                <ul>
                    <li><strong>\( I_x, I_y \)</strong>: Spatial image gradients.</li>
                    <li><strong>\( I_t \)</strong>: Temporal image gradient.</li>
                    <li><strong>\( u, v \)</strong>: Optical flow vectors in x and y directions.</li>
                </ul>
            </article>

            <article>
                <h3>6. Matching and Classification</h3>
                <p>Comparing lip features to recognize or verify individuals.</p>
            </article>

            <article>
                <h4>6.1 Distance Metrics</h4>
                <p>Calculating similarity between feature vectors using:</p>
                <ul>
                    <li><strong>Euclidean Distance</strong>: Measures direct distance between vectors.</li>
                    <li><strong>Dynamic Time Warping (DTW)</strong>: Aligns sequences that may vary in time or speed.</li>
                    <li><strong>Cosine Similarity</strong>: Measures the cosine of the angle between vectors.</li>
                </ul>
                <p>DTW distance between sequences \( Q \) and \( C \):</p>
                <p>$$ DTW(Q, C) = \min_{\pi} \sum_{k=1}^{K} d(q_{\pi_k}, c_{\pi_k}) $$</p>
                <ul>
                    <li><strong>\( \pi \)</strong>: Warping path aligning sequences.</li>
                    <li><strong>\( d \)</strong>: Distance measure between points.</li>
                </ul>
            </article>

            <article>
                <h4>6.2 Classification Algorithms</h4>
                <p>Methods for assigning lip data to identities:</p>
                <ul>
                    <li><strong>Support Vector Machines (SVM)</strong>: Finding the optimal separating hyperplane.</li>
                    <li><strong>Neural Networks</strong>: Learning complex patterns through multiple layers.</li>
                    <li><strong>Hidden Markov Models (HMM)</strong>: Modeling temporal patterns in lip movement.</li>
                </ul>
            </article>

            <article>
                <h3>7. Evaluation Metrics</h3>
                <p>Assessing system performance using statistical measures.</p>
            </article>

            <article>
                <h4>7.1 Accuracy</h4>
                <p>The proportion of correct predictions made by the system.</p>
                <p>Formula:</p>
                <p>$$ \text{Accuracy} = \frac{\text{Number of Correct Predictions}}{\text{Total Number of Predictions}} $$</p>
            </article>

            <article>
                <h4>7.2 Precision and Recall</h4>
                <p>Measures for evaluating classification results.</p>
                <ul>
                    <li><strong>Precision</strong>: Proportion of true positives among all positive predictions.</li>
                    <li><strong>Recall</strong>: Proportion of true positives among all actual positives.</li>
                </ul>
                <p>Formulas:</p>
                <p>$$ \text{Precision} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Positives}} $$</p>
                <p>$$ \text{Recall} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Negatives}} $$</p>
            </article>

            <article>
                <h4>7.3 Receiver Operating Characteristic (ROC) Curve</h4>
                <p>Plotting true positive rate against false positive rate at various thresholds.</p>
                <p>Definitions:</p>
                <ul>
                    <li><strong>True Positive Rate (TPR)</strong>: Also known as recall.</li>
                    <li><strong>False Positive Rate (FPR)</strong>: Proportion of negatives incorrectly identified as positives.</li>
                </ul>
            </article>

            <article>
                <h3>8. Challenges in Lip Biometrics</h3>
                <p>Factors affecting the accuracy and reliability of lip biometric systems.</p>
            </article>

            <article>
                <h4>8.1 Variability in Expressions</h4>
                <p>Changes in facial expressions can alter lip appearance.</p>
                <p>Mitigation strategies:</p>
                <ul>
                    <li><strong>Expression-Invariant Features</strong>: Focusing on features less affected by expressions.</li>
                    <li><strong>Dynamic Analysis</strong>: Modeling lip movements over time.</li>
                </ul>
            </article>

            <article>
                <h4>8.2 Occlusions</h4>
                <p>Obstructions such as facial hair or masks can cover the lips.</p>
                <p>Approaches:</p>
                <ul>
                    <li><strong>Occlusion Detection</strong>: Identifying and excluding occluded regions.</li>
                    <li><strong>Alternative Modalities</strong>: Combining lip biometrics with other methods for enhanced robustness.</li>
                </ul>
            </article>

            <article>
                <h4>8.3 Lighting Conditions</h4>
                <p>Variations in illumination can affect image quality.</p>
                <p>Solutions:</p>
                <ul>
                    <li><strong>Illumination Normalization</strong>: Techniques to standardize lighting effects.</li>
                    <li><strong>Infrared Imaging</strong>: Less sensitive to ambient light changes.</li>
                </ul>
            </article>

            <article>
                <h4>8.4 Speech Variability</h4>
                <p>Differences in speech content and speed can impact dynamic features.</p>
                <p>Strategies:</p>
                <ul>
                    <li><strong>Text-Independent Methods</strong>: Recognizing individuals regardless of spoken content.</li>
                    <li><strong>Adaptive Models</strong>: Accounting for variations in speech patterns.</li>
                </ul>
            </article>

            <article>
                <h3>9. Implementation Example</h3>
                <p>An example of building a lip biometric system using DCT for feature extraction and HMM for classification.</p>
            </article>

            <article>
                <h4>9.1 Data Preparation</h4>
                <p>Steps involved:</p>
                <ol>
                    <li><strong>Collect Lip Videos</strong>: Gather a dataset of lip movement videos with labels.</li>
                    <li><strong>Preprocess Videos</strong>:
                        <ul>
                            <li>Extract frames and convert to grayscale.</li>
                            <li>Detect and segment the lip region in each frame.</li>
                        </ul>
                    </li>
                    <li><strong>Normalize Frames</strong>: Resize and align lip images to a standard size.</li>
                </ol>
            </article>

            <article>
                <h4>9.2 Feature Extraction with DCT</h4>
                <p>Applying DCT to each lip frame to obtain feature vectors.</p>
                <pre><code class="language-python">import numpy as np
import cv2
from scipy.fftpack import dct

def extract_dct_features(image, num_coefficients):
    # Apply 2D DCT
    dct_transformed = dct(dct(image.T, norm='ortho').T, norm='ortho')
    # Flatten and select top coefficients
    dct_flat = dct_transformed.flatten()
    return dct_flat[:num_coefficients]

# Example usage
num_coefficients = 50
features = []
for frame in lip_frames:
    feature_vector = extract_dct_features(frame, num_coefficients)
    features.append(feature_vector)
</code></pre>
                <p>The feature vectors from all frames form a sequence for each video.</p>
            </article>

            <article>
                <h4>9.3 Classification with Hidden Markov Models (HMM)</h4>
                <p>Training HMMs for each individual to model their lip movement patterns.</p>
                <pre><code class="language-python">from hmmlearn import hmm
import numpy as np

# Assuming features_list is a list of feature sequences for each individual
models = {}
for person_id, sequences in features_list.items():
    # Concatenate sequences
    X = np.concatenate(sequences)
    lengths = [len(seq) for seq in sequences]
    # Train HMM
    model = hmm.GaussianHMM(n_components=5, covariance_type='diag', n_iter=100)
    model.fit(X, lengths)
    models[person_id] = model

# Recognizing a new sequence
def recognize(sequence):
    scores = {}
    for person_id, model in models.items():
        score = model.score(sequence)
        scores[person_id] = score
    # Identify the person with the highest score
    identified_person = max(scores, key=scores.get)
    return identified_person
</code></pre>
                <p>HMMs capture temporal dynamics in lip movements.</p>
            </article>

            <article>
                <h4>9.4 Evaluating the System</h4>
                <p>Using test sequences to assess performance.</p>
                <pre><code class="language-python"># Test the recognition function
correct = 0
total = len(test_sequences)
for true_id, sequence in test_sequences.items():
    predicted_id = recognize(sequence)
    if predicted_id == true_id:
        correct += 1

accuracy = correct / total * 100
print(f'Accuracy: {accuracy:.2f}%')
</code></pre>
            </article>

            <article>
                <h3>10. Summary</h3>
                <p>Lip Biometric Systems utilize the unique features of the human lips, including shape, texture, and movement patterns, for personal identification. By understanding the processes of image acquisition, preprocessing, feature extraction, and classification, effective lip recognition applications can be developed. Challenges such as variability in expressions and occlusions can be addressed through appropriate techniques, enhancing the system's accuracy and reliability.</p>
            </article>


        </main>

        <script> copyright("all"); </script>

    </body>

</html>